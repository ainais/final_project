{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http = urllib3.PoolManager()\n",
    "\n",
    "# url ='http://www.manythings.org/anki/kor-eng.zip'\n",
    "\n",
    "filename = 'kor-eng.zip'\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "zipfilename = os.path.join(path, filename)\n",
    "\n",
    "# with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "\n",
    "#     shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "  zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3729, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_csv('kor.txt', names=['en','ko'], sep='\\t', index_col=False)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인사해.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.en[0]='Say hello.'\n",
    "lines.en[0]\n",
    "lines.ko[0]='인사해.'\n",
    "lines.ko[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ko</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Say hello.</td>\n",
       "      <td>\\t 인사해. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en          ko\n",
       "0  Say hello.  \\t 인사해. \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.ko = lines.ko.apply(lambda x: '\\t '+x+' \\n')\n",
    "lines[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# en & ko 글자 집합 구축\n",
    "en_vocab = set()\n",
    "for line in lines.en :\n",
    "  for char in line:\n",
    "    en_vocab.add(char)\n",
    "\n",
    "#print(en_vocab)\n",
    "\n",
    "ko_vocab = set()\n",
    "for line in lines.ko :\n",
    "  for char in line:\n",
    "    ko_vocab.add(char)\n",
    "\n",
    "#print(ko_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "915\n"
     ]
    }
   ],
   "source": [
    "en_vocab_size = len(en_vocab)+1\n",
    "ko_vocab_size = len(ko_vocab)+1\n",
    "print(en_vocab_size)\n",
    "print(ko_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', 'ï']\n",
      "['\\t', '\\n', ' ', '!', '\"', '%', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'H', 'M', 'N', 'T', 'a', 'd', 'h', 'i', 'm', 'o', 'p', 'r', 't', 'y', '°', '가', '각', '간', '갇', '갈', '감', '갑', '값', '갔', '강', '갖', '같', '개', '객', '갰', '걀', '걔', '거', '걱', '건', '걷', '걸', '검', '겁', '것', '게', '겐', '겠', '겨', '격', '겪', '견', '결', '겼', '경', '계', '고', '곡', '곤', '곧', '골', '곰', '곱', '곳', '공', '과', '관', '광', '괜', '괴', '굉', '교', '구', '국', '군', '굳', '굴', '굶', '굼', '굽', '궁', '권', '귀', '귄', '규', '그', '극', '근', '글', '금', '급', '긋', '긍', '기', '긴', '길', '깊', '까', '깎', '깐', '깔', '깜', '깡', '깨', '꺼', '꺾', '껍', '껏', '껐', '께', '껴', '꼈', '꼬', '꼴', '꼼', '꽃', '꽉', '꽤', '꾸', '꾼', '꿇', '꿈', '꿔', '꿨', '뀌', '끄', '끈', '끊', '끌', '끓', '끔', '끗', '끙', '끝', '끼', '낀', '낄', '낌', '나', '낙', '낚', '난', '날', '낡', '남', '납', '났', '낭', '낮', '낯', '내', '낸', '낼', '냄', '냈', '냉', '냐', '냥', '너', '넌', '널', '넓', '넘', '넛', '넣', '네', '넷', '녀', '녁', '년', '념', '녕', '노', '녹', '논', '놀', '농', '높', '놓', '놔', '놨', '뇌', '누', '눅', '눈', '눠', '눴', '뉴', '늄', '느', '늑', '는', '늘', '늙', '능', '늦', '니', '닌', '님', '다', '닥', '닦', '단', '닫', '달', '닮', '담', '답', '당', '대', '댔', '더', '덕', '던', '덜', '덤', '덥', '데', '덴', '도', '독', '돈', '돌', '돕', '동', '돼', '됐', '되', '된', '될', '됩', '두', '둑', '둔', '둘', '둠', '둬', '뒀', '뒤', '뒷', '드', '득', '든', '듣', '들', '듯', '등', '디', '딘', '딨', '따', '딱', '딸', '땅', '땋', '때', '떠', '떡', '떤', '떨', '떴', '떻', '또', '똑', '뚱', '뛰', '뜨', '뜰', '뜻', '라', '락', '란', '랄', '람', '랍', '랐', '랑', '래', '랜', '램', '랩', '랬', '략', '량', '러', '럭', '런', '럴', '럼', '럽', '렀', '렁', '렇', '레', '렌', '렛', '려', '력', '련', '렵', '렸', '령', '례', '로', '록', '론', '롭', '뢰', '료', '루', '룹', '류', '륙', '륜', '륭', '르', '른', '를', '름', '릅', '릎', '리', '린', '릴', '림', '립', '마', '막', '만', '많', '말', '맙', '맛', '망', '맞', '맡', '매', '맥', '맨', '맷', '머', '먹', '먼', '멀', '멈', '멋', '멍', '메', '멕', '멜', '며', '면', '명', '몇', '모', '목', '몰', '몸', '못', '묘', '무', '묵', '묶', '문', '묻', '물', '뭇', '뭐', '뭔', '뭘', '므', '미', '민', '믿', '밀', '밌', '밍', '밑', '바', '박', '밖', '반', '받', '발', '밝', '밟', '밤', '밥', '방', '배', '백', '뱀', '버', '벅', '번', '벌', '범', '법', '벗', '벙', '베', '벼', '벽', '변', '별', '병', '보', '복', '본', '볼', '봄', '봅', '봇', '봉', '봐', '봤', '부', '북', '분', '불', '붉', '붐', '붕', '붙', '브', '블', '비', '빈', '빌', '빙', '빛', '빠', '빨', '빴', '빵', '빼', '뺄', '뻐', '뻔', '뻤', '뽀', '뽑', '뿌', '뿐', '쁘', '쁜', '쁠', '삐', '사', '삭', '산', '살', '삶', '삼', '샀', '상', '새', '색', '샌', '생', '샤', '샴', '서', '석', '선', '설', '섬', '섭', '섯', '섰', '성', '세', '센', '셀', '셈', '셔', '셜', '셨', '소', '속', '손', '솔', '송', '쇠', '수', '숙', '순', '숟', '술', '숨', '쉬', '쉽', '슈', '스', '슨', '슬', '습', '승', '시', '식', '신', '실', '싫', '심', '십', '싱', '싶', '싸', '쌉', '써', '썩', '썼', '썽', '쏘', '쏠', '쏴', '쓰', '쓱', '쓴', '쓸', '씀', '씨', '씩', '씬', '씻', '아', '악', '안', '앉', '않', '알', '앓', '암', '압', '앗', '았', '앙', '앞', '애', '액', '앨', '앵', '야', '약', '얀', '얇', '양', '얗', '얘', '어', '억', '언', '얻', '얼', '엄', '업', '없', '엇', '었', '엌', '에', '엔', '엘', '여', '역', '연', '열', '염', '엽', '였', '영', '옆', '예', '옛', '오', '옥', '온', '올', '옮', '옳', '옷', '옹', '와', '완', '왔', '왜', '외', '왼', '요', '욕', '용', '우', '운', '울', '움', '웃', '워', '원', '월', '웠', '웨', '위', '윈', '윗', '윙', '유', '육', '윤', '으', '은', '을', '음', '읍', '응', '의', '이', '익', '인', '일', '읽', '잃', '임', '입', '있', '잊', '자', '작', '잔', '잖', '잘', '잠', '잡', '잤', '장', '재', '잭', '쟁', '저', '적', '전', '절', '젊', '점', '접', '정', '제', '젝', '젠', '젯', '져', '졌', '조', '족', '존', '졸', '좀', '종', '좋', '좌', '죄', '죠', '주', '죽', '준', '줄', '중', '줘', '줬', '쥐', '즈', '즉', '즐', '즘', '증', '지', '직', '진', '질', '집', '짓', '짖', '짜', '짝', '짧', '째', '쨌', '쩔', '쩡', '쪄', '쪘', '쪼', '쪽', '쫓', '쯤', '찌', '찍', '찔', '찡', '찢', '차', '착', '찬', '찮', '찰', '참', '찼', '창', '찾', '채', '책', '챌', '챘', '처', '척', '천', '철', '첫', '청', '체', '쳐', '쳤', '초', '촌', '총', '최', '추', '축', '출', '춤', '충', '춰', '췄', '취', '츠', '측', '치', '칙', '친', '칠', '침', '칩', '카', '캐', '커', '컨', '컴', '컵', '케', '켓', '켜', '켤', '켰', '코', '콜', '콥', '콩', '쾅', '쿠', '쿨', '퀴', '큐', '크', '큰', '큼', '키', '킬', '킹', '타', '탁', '탄', '탈', '탐', '탑', '탓', '탔', '탕', '태', '택', '터', '턱', '턴', '테', '텐', '토', '톤', '톰', '톱', '통', '퇴', '투', '트', '특', '튼', '틀', '티', '틱', '틴', '팀', '팅', '파', '판', '팔', '팠', '패', '퍼', '펐', '페', '펙', '펜', '펭', '펴', '편', '평', '폐', '포', '폭', '폰', '표', '푸', '푹', '풀', '품', '풍', '퓨', '프', '픈', '플', '픔', '피', '필', '핑', '하', '학', '한', '할', '함', '합', '항', '해', '핸', '햄', '했', '행', '향', '허', '헉', '헌', '험', '헤', '헬', '헷', '혀', '현', '혈', '혐', '협', '혔', '형', '혜', '호', '혹', '혼', '홀', '홋', '화', '확', '환', '활', '황', '회', '획', '효', '후', '훈', '훌', '훔', '훨', '휘', '휴', '흐', '흔', '흘', '흙', '흠', '흡', '흥', '희', '흰', '히', '힌', '힘']\n"
     ]
    }
   ],
   "source": [
    "en_vocab = sorted(list(en_vocab))\n",
    "ko_vocab = sorted(list(ko_vocab))\n",
    "print(en_vocab)\n",
    "print(ko_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '?': 22, 'A': 23, 'B': 24, 'C': 25, 'D': 26, 'E': 27, 'F': 28, 'G': 29, 'H': 30, 'I': 31, 'J': 32, 'K': 33, 'L': 34, 'M': 35, 'N': 36, 'O': 37, 'P': 38, 'Q': 39, 'R': 40, 'S': 41, 'T': 42, 'U': 43, 'V': 44, 'W': 45, 'Y': 46, 'a': 47, 'b': 48, 'c': 49, 'd': 50, 'e': 51, 'f': 52, 'g': 53, 'h': 54, 'i': 55, 'j': 56, 'k': 57, 'l': 58, 'm': 59, 'n': 60, 'o': 61, 'p': 62, 'q': 63, 'r': 64, 's': 65, 't': 66, 'u': 67, 'v': 68, 'w': 69, 'x': 70, 'y': 71, 'z': 72, '°': 73, 'ï': 74}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '%': 6, '(': 7, ')': 8, ',': 9, '-': 10, '.': 11, '/': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'H': 29, 'M': 30, 'N': 31, 'T': 32, 'a': 33, 'd': 34, 'h': 35, 'i': 36, 'm': 37, 'o': 38, 'p': 39, 'r': 40, 't': 41, 'y': 42, '°': 43, '가': 44, '각': 45, '간': 46, '갇': 47, '갈': 48, '감': 49, '갑': 50, '값': 51, '갔': 52, '강': 53, '갖': 54, '같': 55, '개': 56, '객': 57, '갰': 58, '걀': 59, '걔': 60, '거': 61, '걱': 62, '건': 63, '걷': 64, '걸': 65, '검': 66, '겁': 67, '것': 68, '게': 69, '겐': 70, '겠': 71, '겨': 72, '격': 73, '겪': 74, '견': 75, '결': 76, '겼': 77, '경': 78, '계': 79, '고': 80, '곡': 81, '곤': 82, '곧': 83, '골': 84, '곰': 85, '곱': 86, '곳': 87, '공': 88, '과': 89, '관': 90, '광': 91, '괜': 92, '괴': 93, '굉': 94, '교': 95, '구': 96, '국': 97, '군': 98, '굳': 99, '굴': 100, '굶': 101, '굼': 102, '굽': 103, '궁': 104, '권': 105, '귀': 106, '귄': 107, '규': 108, '그': 109, '극': 110, '근': 111, '글': 112, '금': 113, '급': 114, '긋': 115, '긍': 116, '기': 117, '긴': 118, '길': 119, '깊': 120, '까': 121, '깎': 122, '깐': 123, '깔': 124, '깜': 125, '깡': 126, '깨': 127, '꺼': 128, '꺾': 129, '껍': 130, '껏': 131, '껐': 132, '께': 133, '껴': 134, '꼈': 135, '꼬': 136, '꼴': 137, '꼼': 138, '꽃': 139, '꽉': 140, '꽤': 141, '꾸': 142, '꾼': 143, '꿇': 144, '꿈': 145, '꿔': 146, '꿨': 147, '뀌': 148, '끄': 149, '끈': 150, '끊': 151, '끌': 152, '끓': 153, '끔': 154, '끗': 155, '끙': 156, '끝': 157, '끼': 158, '낀': 159, '낄': 160, '낌': 161, '나': 162, '낙': 163, '낚': 164, '난': 165, '날': 166, '낡': 167, '남': 168, '납': 169, '났': 170, '낭': 171, '낮': 172, '낯': 173, '내': 174, '낸': 175, '낼': 176, '냄': 177, '냈': 178, '냉': 179, '냐': 180, '냥': 181, '너': 182, '넌': 183, '널': 184, '넓': 185, '넘': 186, '넛': 187, '넣': 188, '네': 189, '넷': 190, '녀': 191, '녁': 192, '년': 193, '념': 194, '녕': 195, '노': 196, '녹': 197, '논': 198, '놀': 199, '농': 200, '높': 201, '놓': 202, '놔': 203, '놨': 204, '뇌': 205, '누': 206, '눅': 207, '눈': 208, '눠': 209, '눴': 210, '뉴': 211, '늄': 212, '느': 213, '늑': 214, '는': 215, '늘': 216, '늙': 217, '능': 218, '늦': 219, '니': 220, '닌': 221, '님': 222, '다': 223, '닥': 224, '닦': 225, '단': 226, '닫': 227, '달': 228, '닮': 229, '담': 230, '답': 231, '당': 232, '대': 233, '댔': 234, '더': 235, '덕': 236, '던': 237, '덜': 238, '덤': 239, '덥': 240, '데': 241, '덴': 242, '도': 243, '독': 244, '돈': 245, '돌': 246, '돕': 247, '동': 248, '돼': 249, '됐': 250, '되': 251, '된': 252, '될': 253, '됩': 254, '두': 255, '둑': 256, '둔': 257, '둘': 258, '둠': 259, '둬': 260, '뒀': 261, '뒤': 262, '뒷': 263, '드': 264, '득': 265, '든': 266, '듣': 267, '들': 268, '듯': 269, '등': 270, '디': 271, '딘': 272, '딨': 273, '따': 274, '딱': 275, '딸': 276, '땅': 277, '땋': 278, '때': 279, '떠': 280, '떡': 281, '떤': 282, '떨': 283, '떴': 284, '떻': 285, '또': 286, '똑': 287, '뚱': 288, '뛰': 289, '뜨': 290, '뜰': 291, '뜻': 292, '라': 293, '락': 294, '란': 295, '랄': 296, '람': 297, '랍': 298, '랐': 299, '랑': 300, '래': 301, '랜': 302, '램': 303, '랩': 304, '랬': 305, '략': 306, '량': 307, '러': 308, '럭': 309, '런': 310, '럴': 311, '럼': 312, '럽': 313, '렀': 314, '렁': 315, '렇': 316, '레': 317, '렌': 318, '렛': 319, '려': 320, '력': 321, '련': 322, '렵': 323, '렸': 324, '령': 325, '례': 326, '로': 327, '록': 328, '론': 329, '롭': 330, '뢰': 331, '료': 332, '루': 333, '룹': 334, '류': 335, '륙': 336, '륜': 337, '륭': 338, '르': 339, '른': 340, '를': 341, '름': 342, '릅': 343, '릎': 344, '리': 345, '린': 346, '릴': 347, '림': 348, '립': 349, '마': 350, '막': 351, '만': 352, '많': 353, '말': 354, '맙': 355, '맛': 356, '망': 357, '맞': 358, '맡': 359, '매': 360, '맥': 361, '맨': 362, '맷': 363, '머': 364, '먹': 365, '먼': 366, '멀': 367, '멈': 368, '멋': 369, '멍': 370, '메': 371, '멕': 372, '멜': 373, '며': 374, '면': 375, '명': 376, '몇': 377, '모': 378, '목': 379, '몰': 380, '몸': 381, '못': 382, '묘': 383, '무': 384, '묵': 385, '묶': 386, '문': 387, '묻': 388, '물': 389, '뭇': 390, '뭐': 391, '뭔': 392, '뭘': 393, '므': 394, '미': 395, '민': 396, '믿': 397, '밀': 398, '밌': 399, '밍': 400, '밑': 401, '바': 402, '박': 403, '밖': 404, '반': 405, '받': 406, '발': 407, '밝': 408, '밟': 409, '밤': 410, '밥': 411, '방': 412, '배': 413, '백': 414, '뱀': 415, '버': 416, '벅': 417, '번': 418, '벌': 419, '범': 420, '법': 421, '벗': 422, '벙': 423, '베': 424, '벼': 425, '벽': 426, '변': 427, '별': 428, '병': 429, '보': 430, '복': 431, '본': 432, '볼': 433, '봄': 434, '봅': 435, '봇': 436, '봉': 437, '봐': 438, '봤': 439, '부': 440, '북': 441, '분': 442, '불': 443, '붉': 444, '붐': 445, '붕': 446, '붙': 447, '브': 448, '블': 449, '비': 450, '빈': 451, '빌': 452, '빙': 453, '빛': 454, '빠': 455, '빨': 456, '빴': 457, '빵': 458, '빼': 459, '뺄': 460, '뻐': 461, '뻔': 462, '뻤': 463, '뽀': 464, '뽑': 465, '뿌': 466, '뿐': 467, '쁘': 468, '쁜': 469, '쁠': 470, '삐': 471, '사': 472, '삭': 473, '산': 474, '살': 475, '삶': 476, '삼': 477, '샀': 478, '상': 479, '새': 480, '색': 481, '샌': 482, '생': 483, '샤': 484, '샴': 485, '서': 486, '석': 487, '선': 488, '설': 489, '섬': 490, '섭': 491, '섯': 492, '섰': 493, '성': 494, '세': 495, '센': 496, '셀': 497, '셈': 498, '셔': 499, '셜': 500, '셨': 501, '소': 502, '속': 503, '손': 504, '솔': 505, '송': 506, '쇠': 507, '수': 508, '숙': 509, '순': 510, '숟': 511, '술': 512, '숨': 513, '쉬': 514, '쉽': 515, '슈': 516, '스': 517, '슨': 518, '슬': 519, '습': 520, '승': 521, '시': 522, '식': 523, '신': 524, '실': 525, '싫': 526, '심': 527, '십': 528, '싱': 529, '싶': 530, '싸': 531, '쌉': 532, '써': 533, '썩': 534, '썼': 535, '썽': 536, '쏘': 537, '쏠': 538, '쏴': 539, '쓰': 540, '쓱': 541, '쓴': 542, '쓸': 543, '씀': 544, '씨': 545, '씩': 546, '씬': 547, '씻': 548, '아': 549, '악': 550, '안': 551, '앉': 552, '않': 553, '알': 554, '앓': 555, '암': 556, '압': 557, '앗': 558, '았': 559, '앙': 560, '앞': 561, '애': 562, '액': 563, '앨': 564, '앵': 565, '야': 566, '약': 567, '얀': 568, '얇': 569, '양': 570, '얗': 571, '얘': 572, '어': 573, '억': 574, '언': 575, '얻': 576, '얼': 577, '엄': 578, '업': 579, '없': 580, '엇': 581, '었': 582, '엌': 583, '에': 584, '엔': 585, '엘': 586, '여': 587, '역': 588, '연': 589, '열': 590, '염': 591, '엽': 592, '였': 593, '영': 594, '옆': 595, '예': 596, '옛': 597, '오': 598, '옥': 599, '온': 600, '올': 601, '옮': 602, '옳': 603, '옷': 604, '옹': 605, '와': 606, '완': 607, '왔': 608, '왜': 609, '외': 610, '왼': 611, '요': 612, '욕': 613, '용': 614, '우': 615, '운': 616, '울': 617, '움': 618, '웃': 619, '워': 620, '원': 621, '월': 622, '웠': 623, '웨': 624, '위': 625, '윈': 626, '윗': 627, '윙': 628, '유': 629, '육': 630, '윤': 631, '으': 632, '은': 633, '을': 634, '음': 635, '읍': 636, '응': 637, '의': 638, '이': 639, '익': 640, '인': 641, '일': 642, '읽': 643, '잃': 644, '임': 645, '입': 646, '있': 647, '잊': 648, '자': 649, '작': 650, '잔': 651, '잖': 652, '잘': 653, '잠': 654, '잡': 655, '잤': 656, '장': 657, '재': 658, '잭': 659, '쟁': 660, '저': 661, '적': 662, '전': 663, '절': 664, '젊': 665, '점': 666, '접': 667, '정': 668, '제': 669, '젝': 670, '젠': 671, '젯': 672, '져': 673, '졌': 674, '조': 675, '족': 676, '존': 677, '졸': 678, '좀': 679, '종': 680, '좋': 681, '좌': 682, '죄': 683, '죠': 684, '주': 685, '죽': 686, '준': 687, '줄': 688, '중': 689, '줘': 690, '줬': 691, '쥐': 692, '즈': 693, '즉': 694, '즐': 695, '즘': 696, '증': 697, '지': 698, '직': 699, '진': 700, '질': 701, '집': 702, '짓': 703, '짖': 704, '짜': 705, '짝': 706, '짧': 707, '째': 708, '쨌': 709, '쩔': 710, '쩡': 711, '쪄': 712, '쪘': 713, '쪼': 714, '쪽': 715, '쫓': 716, '쯤': 717, '찌': 718, '찍': 719, '찔': 720, '찡': 721, '찢': 722, '차': 723, '착': 724, '찬': 725, '찮': 726, '찰': 727, '참': 728, '찼': 729, '창': 730, '찾': 731, '채': 732, '책': 733, '챌': 734, '챘': 735, '처': 736, '척': 737, '천': 738, '철': 739, '첫': 740, '청': 741, '체': 742, '쳐': 743, '쳤': 744, '초': 745, '촌': 746, '총': 747, '최': 748, '추': 749, '축': 750, '출': 751, '춤': 752, '충': 753, '춰': 754, '췄': 755, '취': 756, '츠': 757, '측': 758, '치': 759, '칙': 760, '친': 761, '칠': 762, '침': 763, '칩': 764, '카': 765, '캐': 766, '커': 767, '컨': 768, '컴': 769, '컵': 770, '케': 771, '켓': 772, '켜': 773, '켤': 774, '켰': 775, '코': 776, '콜': 777, '콥': 778, '콩': 779, '쾅': 780, '쿠': 781, '쿨': 782, '퀴': 783, '큐': 784, '크': 785, '큰': 786, '큼': 787, '키': 788, '킬': 789, '킹': 790, '타': 791, '탁': 792, '탄': 793, '탈': 794, '탐': 795, '탑': 796, '탓': 797, '탔': 798, '탕': 799, '태': 800, '택': 801, '터': 802, '턱': 803, '턴': 804, '테': 805, '텐': 806, '토': 807, '톤': 808, '톰': 809, '톱': 810, '통': 811, '퇴': 812, '투': 813, '트': 814, '특': 815, '튼': 816, '틀': 817, '티': 818, '틱': 819, '틴': 820, '팀': 821, '팅': 822, '파': 823, '판': 824, '팔': 825, '팠': 826, '패': 827, '퍼': 828, '펐': 829, '페': 830, '펙': 831, '펜': 832, '펭': 833, '펴': 834, '편': 835, '평': 836, '폐': 837, '포': 838, '폭': 839, '폰': 840, '표': 841, '푸': 842, '푹': 843, '풀': 844, '품': 845, '풍': 846, '퓨': 847, '프': 848, '픈': 849, '플': 850, '픔': 851, '피': 852, '필': 853, '핑': 854, '하': 855, '학': 856, '한': 857, '할': 858, '함': 859, '합': 860, '항': 861, '해': 862, '핸': 863, '햄': 864, '했': 865, '행': 866, '향': 867, '허': 868, '헉': 869, '헌': 870, '험': 871, '헤': 872, '헬': 873, '헷': 874, '혀': 875, '현': 876, '혈': 877, '혐': 878, '협': 879, '혔': 880, '형': 881, '혜': 882, '호': 883, '혹': 884, '혼': 885, '홀': 886, '홋': 887, '화': 888, '확': 889, '환': 890, '활': 891, '황': 892, '회': 893, '획': 894, '효': 895, '후': 896, '훈': 897, '훌': 898, '훔': 899, '훨': 900, '휘': 901, '휴': 902, '흐': 903, '흔': 904, '흘': 905, '흙': 906, '흠': 907, '흡': 908, '흥': 909, '희': 910, '흰': 911, '히': 912, '힌': 913, '힘': 914}\n"
     ]
    }
   ],
   "source": [
    "# char 별 idx 매칭\n",
    "en_idx = dict([(word, i+1) for i, word in enumerate(en_vocab)])\n",
    "ko_idx = dict([(word, i+1) for i, word in enumerate(ko_vocab)])\n",
    "\n",
    "print(en_idx)\n",
    "print(ko_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41, 47, 71, 1, 54, 51, 58, 58, 61, 9], [30, 55, 9], [40, 67, 60, 2], [40, 67, 60, 9], [45, 54, 61, 22], [45, 61, 69, 2], [28, 55, 64, 51, 2], [30, 51, 58, 62, 2], [32, 67, 59, 62, 2], [32, 67, 59, 62, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 입력 구성\n",
    "encoder_input = []\n",
    "for line in lines.en :\n",
    "  temp_X = []\n",
    "  for w in line:\n",
    "    temp_X.append(en_idx[w])   #char - int 변환\n",
    "  encoder_input.append(temp_X)\n",
    "print(encoder_input[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 641, 472, 862, 11, 3, 2], [1, 3, 551, 195, 11, 3, 2], [1, 3, 289, 573, 4, 3, 2], [1, 3, 289, 573, 11, 3, 2], [1, 3, 206, 96, 24, 3, 2], [1, 3, 615, 606, 4, 3, 2], [1, 3, 539, 4, 3, 2], [1, 3, 243, 606, 690, 4, 3, 2], [1, 3, 666, 848, 4, 3, 2], [1, 3, 666, 848, 862, 11, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 출력 구성\n",
    "decoder_input = []\n",
    "for line in lines.ko :\n",
    "  temp_X = []\n",
    "  for w in line:\n",
    "    temp_X.append(ko_idx[w])   #char - int 변환\n",
    "  decoder_input.append(temp_X)\n",
    "print(decoder_input[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 641, 472, 862, 11, 3, 2], [3, 551, 195, 11, 3, 2], [3, 289, 573, 4, 3, 2], [3, 289, 573, 11, 3, 2], [3, 206, 96, 24, 3, 2], [3, 615, 606, 4, 3, 2], [3, 539, 4, 3, 2], [3, 243, 606, 690, 4, 3, 2], [3, 666, 848, 4, 3, 2], [3, 666, 848, 862, 11, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "# ko column 의 \\t 제거\n",
    "decoder_target = []\n",
    "for line in lines.ko :\n",
    "  t=0\n",
    "  temp_X = []\n",
    "  for w in line:\n",
    "    if t>0:\n",
    "      temp_X.append(ko_idx[w])\n",
    "    t=t+1\n",
    "  decoder_target.append(temp_X)\n",
    "print(decoder_target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# max length\n",
    "max_en_len = max([len(line) for line in lines.en])\n",
    "max_ko_len = max([len(line) for line in lines.ko])\n",
    "\n",
    "print(max_en_len)\n",
    "print(max_ko_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이를 10으로 나누어 사용 (학습 시간 단축)\\n\",\n",
    "max_en_len //= 10\n",
    "max_ko_len //= 10\n",
    "print(max_en_len) \n",
    "print(max_ko_len)  \n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_en_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_ko_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_ko_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 벡터\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **seq2seq 모델** **구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, en_vocab_size))\n",
    "encoder_lstm = LSTM(units=2048, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c] #은닉 상태, 셀 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 75)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 915)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 2048), (None 17399808    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 2048), 24281088    input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 915)    1874835     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 43,555,731\n",
      "Trainable params: 43,555,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(None, ko_vocab_size)) \n",
    "decoder_lstm = LSTM(units=2048, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(ko_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "#adams\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# embedding 계층 관련 학습!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./kopago_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 75)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 2048), (None, 204 17399808  \n",
      "=================================================================\n",
      "Total params: 17,399,808\n",
      "Trainable params: 17,399,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 915)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 2048), 24281088    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 915)    1874835     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 26,155,923\n",
      "Trainable params: 26,155,923\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(2048,))\n",
    "decoder_state_input_c = Input(shape=(2048,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "decoder_states = [state_h, state_c]\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_en = dict((i, char) for char, i in en_idx.items())\n",
    "idx_to_ko = dict((i, char) for char, i in ko_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, ko_vocab_size))\n",
    "    target_seq[0, 0, ko_idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx_to_ko[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_ko_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, ko_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n",
      "53\n",
      "75\n",
      "-----------------------------------\n",
      "입력 문장: Say hello.\n",
      "정답 문장:  인사해. \n",
      "번역기가 번역한 문장:  인사해. \n"
     ]
    }
   ],
   "source": [
    "for i in range(1): # 입력 문장의 인덱스\n",
    "    seq_index = 0\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    print(input_seq)\n",
    "    print(len(input_seq[0]))\n",
    "    print(len(input_seq[0][0]))\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.en[0])\n",
    "    print('정답 문장:', lines.ko[0][1:len(lines.ko[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
