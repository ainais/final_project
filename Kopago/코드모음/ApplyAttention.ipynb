{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kou81\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"conversation.xlsx\")\n",
    "df = df[df['대분류'] == '비즈니스']\n",
    "df = df[df['소분류']=='회의']\n",
    "df = df[df['상황'] == '의견 교환하기']\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'to': 2, 'we': 3, 'i': 4, 'it': 5, 'is': 6, 'of': 7, 'a': 8, 'you': 9, 'for': 10, 'be': 11, 'then': 12, 'that': 13, '네': 14, 'on': 15, 'how': 16, 'about': 17, 'if': 18, 'by': 19, 'in': 20, 'them': 21, 'new': 22, 'was': 23, 'there': 24, '그럼': 25, 'sure': 26, 'need': 27, 'but': 28, 'can': 29, 'as': 30, 'room': 31, 'email': 32, 'should': 33, '더': 34, '것': 35, \"i'll\": 36, 'this': 37, 'are': 38, 'our': 39, 'do': 40, 'yes': 41, \"it's\": 42, 'now': 43, 'will': 44, '이번': 45, '오늘': 46, 'and': 47, 'meeting': 48, 'more': 49, 'with': 50, 'which': 51, 'think': 52, 'use': 53, 'send': 54, 'get': 55, 'check': 56, 'one': 57, 'warehouse': 58, 'what': 59, '다시': 60, '주': 61, '가장': 62, '있나요': 63, '것이': 64, '같아요': 65, '바로': 66, 'have': 67, 'double': 68, 'at': 69, 'last': 70, 'would': 71, 'or': 72, 'probably': 73, 'company': 74, 'tomorrow': 75, '5': 76, 'so': 77, 'know': 78, 'me': 79, 'people': 80, '있습니다': 81, '그렇다면': 82, '새로운': 83, '할': 84, '많이': 85, '저는': 86, '내일': 87, '지금': 88, '있으면': 89, '메일로': 90, '우리': 91, '그': 92, '수': 93, '큰': 94, 'than': 95, \"we'll\": 96, 'call': 97, 'take': 98, 'issues': 99, 'ready': 100, '2': 101, \"we'd\": 102, 'like': 103, 'today': 104, 'go': 105, 'pm': 106, 'better': 107, 'right': 108, 'other': 109, 'please': 110, 'employee': 111, \"didn't\": 112, 'when': 113, 'next': 114, 'from': 115, 'only': 116, 'biggest': 117, 'because': 118, \"don't\": 119, 'commercial': 120, 'work': 121, 'already': 122, 'project': 123, 'final': 124, 'presentation': 125, 'leave': 126, '신제품': 127, '연락해서': 128, '제가': 129, '회의': 130, '시간이': 131, '정도': 132, '먼저': 133, '것은': 134, '생각해요': 135, '어떨까요': 136, '아마': 137, '다음': 138, '어떤': 139, '있는': 140, '두': 141, '모두': 142, '한': 143, '알고': 144, '게': 145, '회사': 146, '이미': 147, '최종': 148, '발표': 149, '어떻게': 150, 'released': 151, 'product': 152, 'increase': 153, 'volume': 154, 'orders': 155, 'make': 156, 'believe': 157, \"let's\": 158, 'materials': 159, 'order': 160, 'items': 161, 'friday': 162, 'time': 163, 'months': 164, 'until': 165, 'soon': 166, 'possible': 167, 'change': 168, 'furniture': 169, 'all': 170, 'going': 171, 'office': 172, \"today's\": 173, \"wouldn't\": 174, 'idea': 175, 'event': 176, 'tell': 177, 'us': 178, 'submit': 179, 'ideas': 180, 'great': 181, 'out': 182, \"they'll\": 183, 'come': 184, 'education': 185, 'program': 186, 'scheduled': 187, 'tuesday': 188, 'products': 189, 'tokyo': 190, 'cost': 191, 'not': 192, 'where': 193, 'information': 194, 'delivered': 195, 'both': 196, 'far': 197, 'let': 198, 'just': 199, 'reason': 200, 'subscription': 201, 'may': 202, 'photos': 203, 'background': 204, 'summer': 205, 'being': 206, 'vacation': 207, 'employees': 208, 'since': 209, 'budget': 210, 'before': 211, 'many': 212, 'again': 213, 'fine': 214, \"company's\": 215, 'website': 216, 'update': 217, 'able': 218, \"i'd\": 219, 'seminar': 220, 'twice': 221, '1': 222, 'tonight': 223, 'thursday': 224, 'told': 225, 'copy': 226, 'machine': 227, 'down': 228, 'few': 229, 'did': 230, 'submitted': 231, '대한': 232, '반응은': 233, '어떤가요': 234, '빠르게': 235, '주문량을': 236, '하죠': 237, '자료는': 238, '조금': 239, '하지만': 240, '중': 241, '바꿔야': 242, '수도': 243, '제일': 244, '오늘이나': 245, '중에': 246, '본사에': 247, '결과도': 248, '너무': 249, '보내는': 250, '아이디어가': 251, '모든': 252, '직원에게': 253, '당장': 254, '메일을': 255, '여러': 256, '교육프로그램이': 257, '않았나요': 258, '확인할': 259, '거에요': 260, '확인해볼게요': 261, '그냥': 262, '교육에': 263, '창고에': 264, '개의': 265, '박스': 266, '배달해야': 267, '다': 268, '생길': 269, '회사의': 270, '좋을까요': 271, '하는': 272, '위해': 273, '예산을': 274, '할까요': 275, '번': 276, '지금은': 277, '없어요': 278, '2배': 279, '많은': 280, '들었어요': 281, '복사기가': 282, '고장': 283, '새로': 284, '해야': 285, '인터넷': 286, '사람이': 287, '참석할': 288, \"market's\": 289, 'reaction': 290, 'newly': 291, 'sales': 292, 'faster': 293, 'previous': 294, 'manufacturer': 295, 'shall': 296, 'look': 297, 'discussed': 298, 'end': 299, \"week's\": 300, 'urgent': 301, 'begin': 302, 'related': 303, 'front': 304, 'mean': 305, 'additional': 306, '000': 307, 'running': 308, 'short': 309, 'manage': 310, 'acceptable': 311, 'delivery': 312, 'gee': 313, 'receive': 314, 'first': 315, 'stationery': 316, 'computers': 317, 'most': 318, 'often': 319, 'tables': 320, 'conference': 321, 'together': 322, 'makes': 323, 'sense': 324, 'also': 325, 'oldest': 326, 'anyone': 327, 'head': 328, 'planning': 329, 'around': 330, 'bring': 331, 'result': 332, 'too': 333, 'late': 334, 'any': 335, 'ask': 336, 'each': 337, 'couple': 338, 'via': 339, \"that's\": 340, 'emails': 341, 'up': 342, 'some': 343, \"isn't\": 344, 'afternoon': 345, 'replaced': 346, 'programs': 347, 'postpone': 348, 'chance': 349, 'shipped': 350, 'sent': 351, 'port': 352, 'ship': 353, 'transported': 354, 'vehicles': 355, 'directly': 356, 'seoul': 357, 'airplane': 358, 'chose': 359, 'current': 360, 'way': 361, 'due': 362, 'why': 363, 'join': 364, 'morning': 365, 'mandatory': 366, 'optional': 367, 'written': 368, 'very': 369, 'small': 370, 'letters': 371, 'bottom': 372, 'notification': 373, 'two': 374, 'boxes': 375, 'necessary': 376, 'deliver': 377, 'needs': 378, 'give': 379, 'moment': 380, 'canceling': 381, 'magazine': 382, 'mainly': 383, 're': 384, 'subscribe': 385, 'once': 386, 'term': 387, 'ends': 388, 'automatic': 389, 'extension': 390, 'problems': 391, 'subscribers': 392, 'kind': 393, 'sea': 394, 'ships': 395, 'cool': 396, 'looking': 397, 'season': 398, 'aside': 399, 'blue': 400, 'color': 401, 'fits': 402, 'image': 403, 'located': 404, 'yangjae': 405, 'store': 406, 'contact': 407, 'clear': 408, 'year': 409, 'officially': 410, 'july': 411, '29': 412, 'august': 413, \"they'd\": 414, 'known': 415, 'notified': 416, 'earlier': 417, 'fix': 418, 'adjust': 419, 'mark': 420, 'parts': 421, 'adjusted': 422, 'separate': 423, 'report': 424, 'hand': 425, 'these': 426, 'reports': 427, 'checked': 428, 'times': 429, 'want': 430, 'they': 431, 'your': 432, 'desk': 433, 'updating': 434, 'okay': 435, 'after': 436, 'three': 437, 'size': 438, 'originally': 439, 'booked': 440, 'expected': 441, 'bigger': 442, 'wonderful': 443, 'reserve': 444, 'instead': 445, 'business': 446, 'trip': 447, \"can't\": 448, 'off': 449, 'start': 450, 'working': 451, 'anything': 452, 'prepare': 453, 'interviewing': 454, 'applicants': 455, \"i'm\": 456, 'sorry': 457, 'oh': 458, 'wednesday': 459, 'either': 460, 'pick': 461, 'date': 462, 'vacant': 463, 'downstairs': 464, 'huge': 465, 'space': 466, 'wasted': 467, 'particular': 468, 'hired': 469, 'including': 470, 'five': 471, 'interns': 472, 'broke': 473, 'called': 474, 'maintenance': 475, 'keeps': 476, 'breaking': 477, \"it'd\": 478, 'buy': 479, 'agree': 480, 'maybe': 481, 'toy': 482, 'month': 483, 'finished': 484, 'design': 485, 'internet': 486, 'commercials': 487, 'procedures': 488, 'left': 489, 'release': 490, 'finish': 491, 'videos': 492, 'media': 493, 'found': 494, 'came': 495, 'started': 496, '6': 497, 'move': 498, '7': 499, 'participants': 500, 'everyone': 501, 'survey': 502, 'week': 503, 'every': 504, 'my': 505, 'floor': 506, 'someone': 507, 'who': 508, 'has': 509, 'yet': 510, 'lot': 511, 'an': 512, 'charity': 513, '출시에': 514, '시장의': 515, '판매량이': 516, '지난번': 517, '제품보다': 518, '늘고': 519, '공장에': 520, '늘려야겠네요': 521, '2배로': 522, '늘리겠습니다': 523, '지난': 524, '마지막에': 525, '논의했던': 526, '안건을': 527, '볼까요': 528, '그보다는': 529, '주제가': 530, '급한': 531, '같습니다': 532, '안건으로': 533, '회의를': 534, '시작하도록': 535, '여러분의': 536, '앞에': 537, '미리': 538, '준비되어': 539, '금요일까지': 540, '2천개를': 541, '주문하라는': 542, '건가요': 543, '촉박하기는': 544, '가능해': 545, '보이는데요': 546, '주문은': 547, '가능하지만': 548, '수령은': 549, '2달': 550, '걸릴': 551, '같네요': 552, '이런': 553, '저희는': 554, '물건을': 555, '최대한': 556, '받고': 557, '싶어요': 558, '사무용품이나': 559, '가구': 560, '뭐라고': 561, '생각하나요': 562, '아무래도': 563, '컴퓨터가': 564, '아닐까요': 565, '쓰니까요': 566, '모두가': 567, '같이': 568, '쓰는': 569, '회의실': 570, '책상을': 571, '한다고': 572, '그럴': 573, '있겠네요': 574, '회사에서': 575, '오래되기도': 576, '했죠': 577, '가시는': 578, '분이': 579, '오후': 580, '5시쯤': 581, '가려고': 582, '했습니다': 583, '함께': 584, '가지고': 585, '가': 586, '주시겠어요': 587, '늦지': 588, '않을까요': 589, '본사로': 590, '빠를': 591, '행사': 592, '진행': 593, '내주세요': 594, '아이디어를': 595, '2개씩': 596, '받으면': 597, '좋은': 598, '생각이네요': 599, '보내야겠어요': 600, '명의': 601, '좋겠죠': 602, '오후에는': 603, '대신': 604, '예정되어있지': 605, '어제': 606, '연기되었다는': 607, '받지': 608, '못했나요': 609, '기회가': 610, '없었어요': 611, '언제로': 612, '연기됐는지': 613, '아시나요': 614, '화요일': 615, '일': 616, '제품은': 617, '방식으로': 618, '도쿄에': 619, '보내지나요': 620, '배로': 621, '도쿄': 622, '근처': 623, '항구까지': 624, '운반하고': 625, '후': 626, '차를': 627, '이용합니다': 628, '서울에서': 629, '비행기로': 630, '낫지': 631, '않나요': 632, '비용이': 633, '들어서': 634, '지금과': 635, '같은': 636, '방법을': 637, '택했습니다': 638, '왜': 639, '오전에': 640, '실시된': 641, '참여하지': 642, '참여하는': 643, '필수가': 644, '아니라': 645, '선택이었어요': 646, '그래요': 647, '내용을': 648, '어디서': 649, '교육': 650, '안내': 651, '메일': 652, '하단에': 653, '작은': 654, '글씨로': 655, '적혀있어요': 656, '박스를': 657, '필요하니까': 658, '전부': 659, '해요': 660, '박스만': 661, '배달하면': 662, '된다고': 663, '있었는데요': 664, '한번': 665, '잠시만': 666, '기다리세요': 667, '잡지의': 668, '구독을': 669, '취소하는': 670, '이유는': 671, '뭔가요': 672, '정기구독': 673, '기간이': 674, '끝나면': 675, '신청하지': 676, '않는': 677, '큽니다': 678, '정기구독을': 679, '자동연장하는': 680, '것으로': 681, '바꾸면': 682, '그렇게': 683, '한다면': 684, '비용': 685, '문제로': 686, '구독자들과': 687, '마찰이': 688, '광고에': 689, '사용할': 690, '사진으로는': 691, '배경에': 692, '바다와': 693, '배들이': 694, '사진이': 695, '좋다고': 696, '곧': 697, '여름이니까': 698, '시원한': 699, '느낌의': 700, '배경을': 701, '고른': 702, '거군요': 703, '꼭': 704, '여름이': 705, '아니어도': 706, '이미지와': 707, '파란색이': 708, '잘': 709, '어울려요': 710, '창고': 711, '창고는': 712, '어느': 713, '지역의': 714, '창고인가요': 715, '양재에': 716, '창고가': 717, '크다고': 718, '있어요': 719, '보관은': 720, '좋겠네요': 721, '그쪽에': 722, '보관을': 723, '비워두도록': 724, '할게요': 725, '올해의': 726, '여름휴가는': 727, '며칠부터': 728, '며칠까지인가요': 729, '7월': 730, '29일부터': 731, '8월': 732, '2일까지가': 733, '공식적인': 734, '기간이에요': 735, '여름휴가를': 736, '기간으로': 737, '전달하면': 738, '될까요': 739, '공지를': 740, '했으니': 741, '다들': 742, '있을': 743, '우리가': 744, '프로젝트의': 745, '수정해야': 746, '재조정할': 747, '필요가': 748, '있다고': 749, '조정이': 750, '필요한': 751, '부분을': 752, '표시해주실래요': 753, '따로': 754, '보고서를': 755, '작성하여': 756, '회의에': 757, '전달할게요': 758, '전에': 759, '이': 760, '보고서들을': 761, '검토해야': 762, '검토를': 763, '마쳤지만': 764, '원한다면': 765, '하셔도': 766, '돼요': 767, '괜찮겠네요': 768, '준비를': 769, '시작하죠': 770, '완성되어': 771, '책상': 772, '위에': 773, '웹사이트를': 774, '업데이트하는': 775, '프로젝트로': 776, '바빠서': 777, '업데이트할': 778, '웹사이트': 779, '업데이트는': 780, '언제쯤': 781, '가능한가요': 782, '늦어도': 783, '괜찮다면': 784, '3달': 785, '뒤에': 786, '가능할': 787, '세미나를': 788, '5호실을': 789, '사용하고': 790, '싶은데요': 791, '원래': 792, '사용하려던': 793, '1호실보다': 794, '공간인데요': 795, '참석예상인원이': 796, '늘어서': 797, '넓은': 798, '공간이': 799, '필요해요': 800, '잘됐네요': 801, '1호실에서': 802, '5호실로': 803, '변경해드릴게요': 804, '혹시': 805, '출장을': 806, '떠날': 807, '어렵고': 808, '짐을': 809, '싸서': 810, '밤에는': 811, '출발이': 812, '가능합니다': 813, '업무를': 814, '있도록': 815, '출발해주세요': 816, '준비해야': 817, '내용이': 818, '보내주세요': 819, '목요일에': 820, '입사': 821, '지원자를': 822, '면접을': 823, '진행하는': 824, '죄송하지만': 825, '그날': 826, '휴가라': 827, '자리에': 828, '아': 829, '화요일이나': 830, '수요일은': 831, '어떠세요': 832, '날짜': 833, '괜찮으니': 834, '편하실': 835, '때로': 836, '잡으세요': 837, '아래층의': 838, '빈': 839, '사무실을': 840, '활용하는': 841, '바꾸기보다는': 842, '일단': 843, '그대로': 844, '두는': 845, '좋겠어요': 846, '두기에는': 847, '공간인데': 848, '무슨': 849, '이유가': 850, '인턴': 851, '5명을': 852, '포함해서': 853, '직원을': 854, '뽑았다고': 855, '또': 856, '나서': 857, '시설': 858, '관리팀에': 859, '연락했어요': 860, '이렇게': 861, '자꾸': 862, '난다면': 863, '사는것이': 864, '낫겠어요': 865, '그러게요': 866, '차라리': 867, '구매를': 868, '원한다고': 869, '말해봐야': 870, '때까지는': 871, '지': 872, '모르겠네요': 873, '출시되는': 874, '장난감에': 875, '프로젝트는': 876, '어디까지': 877, '진행됐나요': 878, '지난달에': 879, '광고를': 880, '위한': 881, '디자인까지': 882, '마쳤습니다': 883, '광고': 884, '외에': 885, '출시까지': 886, '남은': 887, '과정은': 888, '무엇이': 889, '외': 890, '다른': 891, '광고매체': 892, '영상': 893, '마무리': 894, '등이': 895, '남아있습니다': 896, '세미나에': 897, '참석한': 898, '사람의': 899, '수가': 900, '매우': 901, '적던데요': 902, '세미나': 903, '6시여서': 904, '그런': 905, '시간': 906, '늦추면': 907, '있을까요': 908, '그럼요': 909, '지금보다': 910, '정도는': 911, '지난주에': 912, '요청한': 913, '직원용': 914, '설문지는': 915, '제출했나요': 916, '저희': 917, '층의': 918, '직원들은': 919, '제출했다고': 920, '아직': 921, '제출하지': 922, '않은': 923, '하나요': 924, '인원이': 925, '적으면': 926, '전화로': 927, '많으면': 928, '안내해야겠네요': 929, '지난주': 930, '금요일에': 931, '열린': 932, '자선행사의': 933, '어땠나요': 934}\n"
     ]
    }
   ],
   "source": [
    "# 이것은 일종의 매퍼역할이다. 인덱스를 일치시켜준다는 개념으로 사용하고 import 할 데이터를 이거와 매칭시켜주는 것으로 만들자.\n",
    "real_text = []\n",
    "lines_en = []\n",
    "lines_ko = []\n",
    "for i in range(101):\n",
    "    real_text.append(df['번역문'][i])\n",
    "    lines_en.append(df['번역문'][i])\n",
    "\n",
    "for j in range(101):\n",
    "    real_text.append(df['원문'][j])\n",
    "    lines_ko.append(df['원문'][j])\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(real_text)\n",
    "tkIndex = tokenizer.word_index\n",
    "print(tkIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the market's reaction to the newly released product?\n",
      "[16, 6, 1, 289, 290, 2, 1, 291, 151, 152]\n",
      "[ 16   6   1 289 290   2   1 291 151 152   0   0   0   0   0   0   0   0\n",
      "   0   0   0]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "sequences = tokenizer.texts_to_sequences(real_text)\n",
    "padded = pad_sequences(sequences,padding = \"post\")\n",
    "\n",
    "# 확인\n",
    "print(real_text[0])\n",
    "print(sequences[0])\n",
    "print(padded[0])\n",
    "\n",
    "print(len(padded[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_en = tokenizer.texts_to_sequences(lines_en)\n",
    "lines_ko = tokenizer.texts_to_sequences(lines_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513}\n",
      "{14, 25, 34, 35, 45, 46, 60, 61, 62, 63, 64, 65, 66, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934}\n"
     ]
    }
   ],
   "source": [
    "# en & ko 글자 집합 구축\n",
    "en_vocab = set()\n",
    "for line in lines_en :\n",
    "  for char in line:\n",
    "    en_vocab.add(char)\n",
    "\n",
    "print(en_vocab)\n",
    "\n",
    "ko_vocab = set()\n",
    "for line in lines_ko :\n",
    "  for char in line:\n",
    "    ko_vocab.add(char)\n",
    "\n",
    "print(ko_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513\n",
      "935\n"
     ]
    }
   ],
   "source": [
    "# en_vocab_size = len(en_vocab)+1\n",
    "# ko_vocab_size = len(ko_vocab)+1\n",
    "en_vocab_size = 513\n",
    "ko_vocab_size = 935\n",
    "print(en_vocab_size)\n",
    "print(ko_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 127, 514, 232, 515, 233, 234]\n"
     ]
    }
   ],
   "source": [
    "print(lines_ko[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# max length\n",
    "max_en_len = max([len(line) for line in lines_en])\n",
    "max_ko_len = max([len(line) for line in lines_ko])\n",
    "\n",
    "print(max_en_len)\n",
    "print(max_ko_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = lines_en\n",
    "decoder_input = lines_ko\n",
    "decoder_target = lines_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이를 10으로 나누어 사용 (학습 시간 단축)\\n\",\n",
    "max_en_len //= 10\n",
    "max_ko_len //= 10\n",
    "print(max_en_len) \n",
    "print(max_ko_len)  \n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_en_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_ko_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_ko_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 벡터\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **seq2seq 모델** **구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, en_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c] #은닉 상태, 셀 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 513)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 935)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 788480      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  1220608     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 935)    240295      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,249,383\n",
      "Trainable params: 2,249,383\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(None, ko_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(ko_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "#adams\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# embedding 계층 관련 학습!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 935) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 935), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 935).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:414 call\n        return self._run_internal_graph(\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py:716 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:214 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer lstm_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 935)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f500707ceb78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:414 call\n        return self._run_internal_graph(\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py:716 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\kou81\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:214 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer lstm_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 935)\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
